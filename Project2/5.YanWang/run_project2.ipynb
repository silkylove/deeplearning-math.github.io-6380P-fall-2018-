{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim import Adam, RMSprop\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    r\"\"\"\n",
    "        This criterion is a implemenation of Focal Loss, which is proposed in \n",
    "        Focal Loss for Dense Object Detection.\n",
    "            \n",
    "            Loss(x, class) = - \\alpha (1-softmax(x)[class])^gamma \\log(softmax(x)[class])\n",
    "    \n",
    "        The losses are averaged across observations for each minibatch.\n",
    "        Args:\n",
    "            alpha(1D Tensor, Variable) : the scalar factor for this criterion\n",
    "            gamma(float, double) : gamma > 0; reduces the relative loss for well-classiﬁed examples (p > .5), \n",
    "                                   putting more focus on hard, misclassiﬁed examples\n",
    "            size_average(bool): size_average(bool): By default, the losses are averaged over observations for each minibatch.\n",
    "                                However, if the field size_average is set to False, the losses are\n",
    "                                instead summed for each minibatch.\n",
    "    \"\"\"\n",
    "    def __init__(self, class_num, alpha=None, gamma=2, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        if alpha is None:\n",
    "            self.alpha = Variable(torch.ones(class_num, 1))\n",
    "        else:\n",
    "            if isinstance(alpha, Variable):\n",
    "                self.alpha = alpha\n",
    "            else:\n",
    "                self.alpha = Variable(alpha)\n",
    "        self.gamma = gamma\n",
    "        self.class_num = class_num\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        N = inputs.size(0)\n",
    "        C = inputs.size(1)\n",
    "        P = F.softmax(inputs)\n",
    "\n",
    "        class_mask = inputs.data.new(N, C).fill_(0)\n",
    "        class_mask = Variable(class_mask)\n",
    "        ids = targets.view(-1, 1)\n",
    "        class_mask.scatter_(1, ids.data, 1.)\n",
    "        #print(class_mask)\n",
    "        \n",
    "\n",
    "        if inputs.is_cuda and not self.alpha.is_cuda:\n",
    "            self.alpha = self.alpha.cuda()\n",
    "        alpha = self.alpha[ids.data.view(-1)]\n",
    "        \n",
    "        probs = (P*class_mask).sum(1).view(-1,1)\n",
    "\n",
    "        log_p = probs.log()\n",
    "\n",
    "        batch_loss = -alpha*(torch.pow((1-probs), self.gamma))*log_p \n",
    "        \n",
    "        if self.size_average:\n",
    "            loss = batch_loss.mean()\n",
    "        else:\n",
    "            loss = batch_loss.sum()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(*models):\n",
    "    for model in models:\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "                nn.init.kaiming_normal(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                module.weight.data.fill_(1)\n",
    "                module.bias.data.zero_()\n",
    "        \n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_channel_input=1, n_channel_output=1):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv_stage_1 = nn.Sequential(\n",
    "            nn.Conv2d(n_channel_input, 64, kernel_size=7, stride=1, padding=3), # 224\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 112\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 56\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 28\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 14\n",
    "            nn.Conv2d(384, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 7\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512*7*7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, n_channel_output),\n",
    "        )\n",
    "        \n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size()[0]\n",
    "        x_stage_1 = self.conv_stage_1(x)\n",
    "        x_stage_1 = x_stage_1.view(x.size(0), 512*7*7)\n",
    "        output = self.classifier(x_stage_1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(object):\n",
    "    '''\n",
    "        Discriminator Network\n",
    "    '''\n",
    "    def __init__(self, D):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # define hyper-parameters\n",
    "        self.batch_size_train = 10\n",
    "        self.batch_size_validation = 10\n",
    "        \n",
    "        # construct D\n",
    "        self.D = D\n",
    "        \n",
    "        # define learning rate\n",
    "        self.d_lr = 1e-3\n",
    "        \n",
    "        # define RMSprop optimizers for D and S\n",
    "        self.d_optimizer = torch.optim.Adam(self.D.parameters(), lr=self.d_lr)\n",
    "        \n",
    "        # set training iterations\n",
    "        self.epoches = 100\n",
    "\n",
    "        # store losses\n",
    "        self.D_train_loss_list = []\n",
    "        self.D_validation_accuracy_list = []\n",
    "        \n",
    "        self.X_D_train = []\n",
    "        self.X_D_validation = []\n",
    "        \n",
    "        # set CUDA state\n",
    "        self.cuda = True\n",
    "        self.D.cuda()\n",
    "        \n",
    "        # define loss functions\n",
    "        self.CrossEntropyLoss = nn.CrossEntropyLoss().cuda()\n",
    "        self.FocalLoss = FocalLoss(class_num=2).cuda()\n",
    "        \n",
    "    # set requies_grad=Fasle to avoid computation\n",
    "    def set_requires_grad(self, nets, requires_grad=False):\n",
    "        if not isinstance(nets, list):\n",
    "            nets = [nets]\n",
    "        for net in nets:\n",
    "            if net is not None:\n",
    "                for param in net.parameters():\n",
    "                    param.requires_grad = requires_grad\n",
    "    \n",
    "    def train(self, train_dataset, validation_dataset):\n",
    "        \n",
    "        for epoch in range(self.epoches):\n",
    "            \n",
    "            # Load dataset each epoch with SHUFFLE\n",
    "            train_loader = DataLoader(train_dataset, num_workers=4, batch_size=self.batch_size_train, shuffle=True)\n",
    "            \n",
    "            validation_loader = DataLoader(validation_dataset, num_workers=4, batch_size=self.batch_size_validation, shuffle=True)\n",
    "            iter_validation = iter(validation_loader)\n",
    "            \n",
    "            train_loss = 0\n",
    "            validation_accuracy = 0\n",
    "            \n",
    "            count_train = 0\n",
    "            count_validation = 0\n",
    "            \n",
    "            for step, (images, targets) in enumerate(train_loader):\n",
    "                \n",
    "                # Check for batch to have full batch_size\n",
    "                if images.size()[0] != self.batch_size_train:\n",
    "                    break\n",
    "                    \n",
    "                # Load each batch\n",
    "                images = Variable(images.cuda())\n",
    "                targets = Variable(targets.cuda())\n",
    "\n",
    "                self.set_requires_grad(self.D, True)\n",
    "                \n",
    "                # Train D\n",
    "                self.d_optimizer.zero_grad()\n",
    "                \n",
    "                d_predictions = self.D(images)\n",
    "                # print(F.sigmoid(d_predictions))\n",
    "                d_loss = self.FocalLoss(d_predictions, targets)\n",
    "                d_loss.backward()\n",
    "                \n",
    "                # Optimize D\n",
    "                self.d_optimizer.step()  \n",
    "                \n",
    "                '''\n",
    "                batch_train_accuracy = accuracy_score(targets.cpu().data.float().numpy().tolist(), \n",
    "                                     np.argmax(F.softmax(d_predictions).cpu().data.numpy(), axis=1).tolist())\n",
    "                train_accuracy = train_accuracy + batch_train_accuracy\n",
    "                '''\n",
    "                print(\"Train loss of batch %d of epoch %d: %f.\" % (step, epoch, d_loss.item()))\n",
    "                \n",
    "                train_loss = train_loss + d_loss.item()\n",
    "                count_train = count_train + 1\n",
    "                \n",
    "                if step % 18 == 0:\n",
    "                    \n",
    "                    images_validation, targets_validation = iter_validation.next()\n",
    "\n",
    "                    images_validation = Variable(images_validation.cuda())\n",
    "                    targets_validation = Variable(targets_validation.cuda())\n",
    "\n",
    "                    d_predictions_validation = self.D.forward(images_validation)\n",
    "\n",
    "                    batch_validation_accuracy = accuracy_score(targets_validation.cpu().data.float().numpy().tolist(), \n",
    "                                         np.argmax(F.softmax(d_predictions_validation).cpu().data.numpy(), axis=1).tolist())\n",
    "                    validation_accuracy = validation_accuracy + batch_validation_accuracy\n",
    "                    print(\"Validation accuracy of batch %d of epoch %d: %f.\" % (count_validation, epoch, batch_validation_accuracy))\n",
    "                    print(\"---------------------------------------------------------------\")\n",
    "                    \n",
    "                    count_validation = count_validation + 1\n",
    "\n",
    "            self.D_train_loss_list.append(train_loss / count_train)\n",
    "            self.X_D_train.append(epoch)\n",
    "            \n",
    "            self.D_validation_accuracy_list.append(batch_validation_accuracy / count_validation)   \n",
    "            self.X_D_validation.append(epoch)\n",
    "                \n",
    "            clear_output(wait=True)\n",
    "            plt.plot(self.X_D_train, self.D_train_loss_list, 'r--', \n",
    "                     self.X_D_validation, self.D_validation_accuracy_list, 'g^')\n",
    "            plt.show()           \n",
    "            \n",
    "            torch.save(self.D, './model/Alexnet_trained_model_focal_'+str(epoch)+'.pt')\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load the complete datasets for training and validation\n",
    "    dataset_NEXPERIA_train = datasets.ImageFolder('./data/train/',\n",
    "                                 transforms.Compose([\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 # normalize,\n",
    "                             ]))\n",
    "    \n",
    "    dataset_NEXPERIA_validation = datasets.ImageFolder('./data/validation/',\n",
    "                                 transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 # normalize,\n",
    "                             ]))\n",
    "        \n",
    "    D = AlexNet(n_channel_input=3, n_channel_output=2)\n",
    "    # D = torch.load('./model/Alexnet_trained_model_focal_0.pt')\n",
    "    \n",
    "    model = Discriminator(D)\n",
    "    model.train(dataset_NEXPERIA_train, dataset_NEXPERIA_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dataset_NEXPERIA = datasets.ImageFolder('./data/validation/',\n",
    "                                 transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 # normalize,\n",
    "                             ]))\n",
    "\n",
    "train_loader = DataLoader(dataset_NEXPERIA, num_workers=4, batch_size=1, shuffle=True)\n",
    "\n",
    "predictions_0 = []\n",
    "labels_0 = []\n",
    "predictions_1 = []\n",
    "labels_1 = []\n",
    "\n",
    "D = AlexNet(n_channel_input=3, n_channel_output=2)\n",
    "D = torch.load('./model/Alexnet_trained_model_focal_5.pt')\n",
    "\n",
    "for step, (images, targets) in enumerate(train_loader):\n",
    "\n",
    "    # Load each batch\n",
    "    images = Variable(images.cuda())\n",
    "    targets = Variable(targets.cuda())\n",
    "\n",
    "    d_predictions = F.softmax(D(images))\n",
    "\n",
    "    if targets.cpu().data.numpy()[0] == 0:\n",
    "        predictions_0.append(np.argmax(d_predictions.cpu().data.numpy()))\n",
    "        labels_0.append(targets.cpu().data.numpy()[0])\n",
    "    else:\n",
    "        predictions_1.append(np.argmax(d_predictions.cpu().data.numpy()))\n",
    "        labels_1.append(targets.cpu().data.numpy()[0])\n",
    "    \n",
    "    if step % 1000 == 0:\n",
    "        print(\"Accuracy of first %d samples: %f for 0 samples and %f for 1 samples.\" % \n",
    "            (step, accuracy_score(labels_0, predictions_0), accuracy_score(labels_1, predictions_1)))\n",
    "              \n",
    "print(\"Accuracy of all 0 samples: %f.\" % accuracy_score(labels_0, predictions_0))\n",
    "print(\"Accuracy of all 1 samples: %f.\" % accuracy_score(labels_1, predictions_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "dataset_NEXPERIA = datasets.ImageFolder('./data/validation/',\n",
    "                                 transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 # normalize,\n",
    "                             ]))\n",
    "\n",
    "train_loader = DataLoader(dataset_NEXPERIA, num_workers=4, batch_size=1, shuffle=True)\n",
    "\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "D = AlexNet(n_channel_input=3, n_channel_output=2)\n",
    "D = torch.load('./model/Alexnet_trained_model_focal_5.pt')\n",
    "\n",
    "for step, (images, targets) in enumerate(train_loader):\n",
    "\n",
    "    # Load each batch\n",
    "    images = Variable(images.cuda())\n",
    "    targets = Variable(targets.cuda())\n",
    "\n",
    "    d_predictions = F.softmax(D(images))\n",
    "    \n",
    "    label = np.argmax(d_predictions.cpu().data.numpy())\n",
    "    labels.append(targets.cpu().data)\n",
    "    \n",
    "    if label == 0:\n",
    "        predictions.append(1.0 - d_predictions.cpu().data.numpy()[0,0])\n",
    "    else:\n",
    "        predictions.append(d_predictions.cpu().data.numpy()[0,1])\n",
    "        \n",
    "roc_auc_score(labels, predictions, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "EXTENSIONS = ['.jpg', '.png', 'mat']\n",
    "\n",
    "def load_image(file):\n",
    "    return Image.open(file)\n",
    "\n",
    "def is_image(filename):\n",
    "    return any(filename.endswith(ext) for ext in EXTENSIONS)\n",
    "\n",
    "def image_path(root, basename, extension):\n",
    "    return os.path.join(root, basename+extension)\n",
    "\n",
    "def image_basename(filename):\n",
    "    return os.path.basename(os.path.splitext(filename)[0])\n",
    "\n",
    "class NEXPERIA(Dataset):\n",
    "\n",
    "    def __init__(self, root):\n",
    "        self.images_root = os.path.join(root, 'image')\n",
    "\n",
    "        self.filenames = [image_basename(f)\n",
    "            for f in os.listdir(self.images_root) if is_image(f)]\n",
    "        self.filenames.sort()\n",
    "\n",
    "        self.input_transform = Compose([\n",
    "            ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.filenames[index]\n",
    "\n",
    "        with open(image_path(self.images_root, filename, '.jpg'), 'rb') as f:\n",
    "            image = load_image(f).convert('RGB')\n",
    "        \n",
    "        if self.input_transform is not None:\n",
    "            image = self.input_transform(image)\n",
    "\n",
    "        return image, filename\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "dataset_NEXPERIA_test = NEXPERIA('./data/test')\n",
    "\n",
    "test_loader = DataLoader(dataset_NEXPERIA_test, num_workers=4, batch_size=1, shuffle=False)\n",
    "\n",
    "D = AlexNet(n_channel_input=3, n_channel_output=2)\n",
    "D = torch.load('./model/Alexnet_trained_model_focal_5.pt')\n",
    "\n",
    "with open('./data/submission.csv', 'w') as f:\n",
    "    \n",
    "    writer = csv.writer(f)\n",
    "    \n",
    "    header = ['id', 'label']\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for step, (image, filename) in enumerate(test_loader):\n",
    "\n",
    "        # Load each batch\n",
    "        image = Variable(image.cuda())\n",
    "\n",
    "        d_predictions = F.softmax(D(image))\n",
    "\n",
    "        label = np.argmax(d_predictions.cpu().data.numpy())\n",
    "\n",
    "        if label == 0:\n",
    "            prob = 1.0 - d_predictions.cpu().data.numpy()[0,0]\n",
    "        else:\n",
    "            prob = d_predictions.cpu().data.numpy()[0,1]\n",
    "        \n",
    "        row = [filename[0], float(prob)]\n",
    "        writer.writerow(row)\n",
    "        \n",
    "        print(filename[0])\n",
    "        \n",
    "f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
